import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.ensemble import IsolationForest
from io import BytesIO

# Set the seaborn style for better aesthetics
sns.set_style("whitegrid")

def upload_dataset():
    """
    Allows users to upload a dataset in CSV, Excel, or other supported formats.

    Returns:
        pd.DataFrame: The uploaded dataset as a pandas DataFrame.
    """
    uploaded_file = st.file_uploader("ğŸ“¥ **Upload Your Dataset**", type=["csv", "xlsx", "xls"])
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.success("âœ… Dataset uploaded successfully!")
            st.write(f"**Dataset Shape:** {df.shape}")
            st.dataframe(df.head())
            return df
        except Exception as e:
            st.error(f"âŒ Error loading dataset: {e}")
    return None

def filter_cases(df):
    """
    Provides functionality to filter instances (rows) based on user-defined conditions.

    Args:
        df (pd.DataFrame): The original dataset.

    Returns:
        pd.DataFrame: The filtered dataset.
    """
    st.header("ğŸ” **Filter Cases**")

    st.markdown("""
    ### Apply Filter Conditions
    Enter your filter conditions using pandas `query` syntax.

    - **Logical Operators:** `and`, `or`, `not`
    - **Comparison Operators:** `>`, `<`, `>=`, `<=`, `==`, `!=`
    - **String Values:** Enclose string literals in single (`'`) or double (`"`) quotes.

    **Examples:**
    - `AGE > 30`
    - `INCOME < 50000 and AGE >= 25`
    - `CITY == 'New York' or CITY == 'Los Angeles'`
    """)

    filter_condition = st.text_area(
        "ğŸ“‹ **Enter Filter Conditions**",
        height=150,
        placeholder="e.g., AGE > 30 and INCOME < 50000"
    )

    if st.button("ğŸ”„ Apply Filter"):
        if filter_condition.strip() == "":
            st.warning("âš ï¸ Please enter at least one filter condition.")
            return df
        try:
            # Use query to filter the dataframe
            filtered_df = df.query(filter_condition, engine='python')
            st.success("âœ… Filter applied successfully!")
            st.write(f"**Number of records after filtering:** {filtered_df.shape[0]}")
            st.dataframe(filtered_df.head())
            return filtered_df
        except Exception as e:
            st.error(f"âŒ Error applying filter: {e}")
            st.info("ğŸ” Ensure your filter conditions are valid and match the dataset's column names and data types.")
            return df
    else:
        st.write(f"**Number of records after filtering:** {df.shape[0]}")
        return df

def aggregate_scores(df):
    """
    Enables users to create a composite score by aggregating selected numerical columns.

    Args:
        df (pd.DataFrame): The dataset to aggregate.

    Returns:
        pd.DataFrame: Dataset with an additional 'Composite_Score' column.
    """
    st.header("ğŸ§® **Score Aggregation**")
    numeric_columns = df.select_dtypes(include=['number']).columns.tolist()
    if not numeric_columns:
        st.warning("âš ï¸ No numerical columns available for aggregation.")
        return df

    selected_columns = st.multiselect(
        "ğŸ“Š **Select Columns to Aggregate into a Score**", 
        numeric_columns,
        default=numeric_columns[:2]  # Default selection
    )
    
    if selected_columns:
        aggregation_method = st.selectbox(
            "ğŸ”§ **Select Aggregation Method**", 
            ["Sum", "Mean", "Weighted Sum"]
        )
        if aggregation_method == "Sum":
            df['Composite_Score'] = df[selected_columns].sum(axis=1)
            st.success("âœ… Composite score (Sum) created successfully!")
        elif aggregation_method == "Mean":
            df['Composite_Score'] = df[selected_columns].mean(axis=1)
            st.success("âœ… Composite score (Mean) created successfully!")
        elif aggregation_method == "Weighted Sum":
            weights = {}
            st.markdown("### âš–ï¸ **Assign Weights**")
            for col in selected_columns:
                weights[col] = st.number_input(
                    f"Weight for `{col}`", 
                    value=1.0, 
                    step=0.1,
                    format="%.2f"
                )
            weights_series = pd.Series(weights)
            df['Composite_Score'] = df[selected_columns].mul(weights_series).sum(axis=1)
            st.success("âœ… Composite score (Weighted Sum) created successfully!")
        st.write("### ğŸ“ˆ **Composite Score Statistics**")
        st.write(df[['Composite_Score']].describe())
    else:
        st.warning("âš ï¸ Please select at least one column to aggregate.")
    return df

def plot_monovariate_distribution(df):
    """
    Visualizes the distribution of individual numerical variables.

    Args:
        df (pd.DataFrame): The dataset to visualize.
    """
    st.header("ğŸ“Š **Monovariate Distribution**")
    numeric_columns = df.select_dtypes(include=['number']).columns.tolist()
    if not numeric_columns:
        st.warning("âš ï¸ No numerical columns available for visualization.")
        return
    selected_column = st.selectbox("ğŸ” **Select a Numerical Column to Visualize**", numeric_columns)
    
    if selected_column:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(df[selected_column].dropna(), kde=True, ax=ax, color='skyblue', edgecolor='black')
        ax.set_title(f"ğŸ“ˆ **Distribution of `{selected_column}`**", fontsize=16)
        ax.set_xlabel(selected_column, fontsize=14)
        ax.set_ylabel("Frequency", fontsize=14)
        st.pyplot(fig)

def plot_multivariate_distribution(df):
    """
    Visualizes the distribution of multiple numerical variables using pair plots or scatter plots.

    Args:
        df (pd.DataFrame): The dataset to visualize.
    """
    st.header("ğŸ“ˆ **Multivariate Distribution**")
    numeric_columns = df.select_dtypes(include=['number']).columns.tolist()
    if len(numeric_columns) < 2:
        st.warning("âš ï¸ At least two numerical columns are required for multivariate visualization.")
        return
    selected_columns = st.multiselect(
        "ğŸ” **Select Numerical Columns to Visualize**", 
        numeric_columns, 
        default=numeric_columns[:2]
    )
    
    if len(selected_columns) >= 2:
        plot_type = st.selectbox("ğŸ”§ **Select Plot Type**", ["Pair Plot", "Scatter Plot"])
        if plot_type == "Pair Plot":
            with st.spinner("Generating Pair Plot..."):
                fig = sns.pairplot(df[selected_columns].dropna())
                st.pyplot(fig)
        elif plot_type == "Scatter Plot":
            x_axis = st.selectbox("ğŸ“ **X-axis**", selected_columns, index=0)
            y_axis = st.selectbox("ğŸ“ **Y-axis**", selected_columns, index=1)
            hue_option = None
            if 'Outlier' in df.columns:
                # Ensure 'Outlier' is boolean and has no NaNs
                df['Outlier'] = df['Outlier'].fillna(False).astype(bool)
                hue_option = 'Outlier'
            fig, ax = plt.subplots(figsize=(10, 6))
            if hue_option:
                # Check if 'Outlier' column has more than one unique value to avoid warning
                if df[hue_option].nunique() > 1:
                    sns.scatterplot(
                        data=df, 
                        x=x_axis, 
                        y=y_axis, 
                        hue=hue_option,
                        palette={True: 'red', False: 'blue'},
                        ax=ax,
                        alpha=0.7
                    )
                else:
                    # If 'Outlier' has only one unique value, skip hue
                    sns.scatterplot(
                        data=df, 
                        x=x_axis, 
                        y=y_axis, 
                        ax=ax,
                        color='blue',
                        alpha=0.7
                    )
                    st.warning("âš ï¸ 'Outlier' column has only one unique value. Hue parameter is ignored.")
            else:
                sns.scatterplot(
                    data=df, 
                    x=x_axis, 
                    y=y_axis, 
                    ax=ax,
                    color='blue',
                    alpha=0.7
                )
            ax.set_title(f"ğŸ“‰ **Scatter Plot of `{x_axis}` vs `{y_axis}`**", fontsize=16)
            st.pyplot(fig)
    else:
        st.warning("âš ï¸ Please select at least two numerical columns for multivariate visualization.")

def choose_statistical_test():
    """
    Allows users to select a statistical test for outlier detection.

    Returns:
        str: The name of the selected statistical test.
    """
    st.sidebar.header("ğŸ” **Outlier Detection Settings**")
    test = st.sidebar.selectbox(
        "ğŸ› ï¸ **Select a Statistical Test to Detect Outliers**", 
        ["Z-Score", "IQR", "DBSCAN", "Isolation Forest"]
    )
    
    # Educational Information about the selected test
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“š **About the Selected Test**")
    
    if test == "Z-Score":
        st.sidebar.markdown("""
        **Z-Score Method**
        
        - **Description:** Measures how many standard deviations an element is from the mean.
        - **Usage:** Suitable for data with a normal distribution.
        - **Outlier Criteria:** Typically, a Z-Score above 3 or below -3 is considered an outlier.
        """)
    elif test == "IQR":
        st.sidebar.markdown("""
        **Interquartile Range (IQR) Method**
        
        - **Description:** Uses the spread of the middle 50% of the data to identify outliers.
        - **Usage:** Suitable for data with skewed distributions.
        - **Outlier Criteria:** Values below Q1 - 1.5*IQR or above Q3 + 1.5*IQR are considered outliers.
        """)
    elif test == "DBSCAN":
        st.sidebar.markdown("""
        **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**
        
        - **Description:** A clustering algorithm that identifies outliers as points not belonging to any cluster.
        - **Usage:** Suitable for data with clusters of similar density.
        - **Parameters:**
          - **eps:** Maximum distance between two samples for them to be considered in the same neighborhood.
          - **min_samples:** Minimum number of samples in a neighborhood to form a core point.
        """)
    elif test == "Isolation Forest":
        st.sidebar.markdown("""
        **Isolation Forest**
        
        - **Description:** An ensemble-based algorithm that isolates observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.
        - **Usage:** Effective for high-dimensional datasets.
        - **Parameters:**
          - **contamination:** The proportion of outliers in the data set.
        """)
    return test

def identify_outliers(df, test):
    """
    Identifies outliers in the dataset based on the selected statistical test.

    Args:
        df (pd.DataFrame): The dataset to analyze.
        test (str): The statistical test selected for outlier detection.

    Returns:
        pd.DataFrame: Dataset with an additional 'Outlier' column indicating outliers.
    """
    st.header("ğŸ” **Outlier Identification**")
    numeric_columns = df.select_dtypes(include=['number']).columns.tolist()
    if not numeric_columns:
        st.warning("âš ï¸ No numerical columns available for outlier detection.")
        return df
    selected_columns = st.multiselect(
        "ğŸ“‹ **Select Numerical Columns for Outlier Detection**", 
        numeric_columns, 
        default=numeric_columns[:2]
    )
    
    if selected_columns:
        if test == "Z-Score":
            threshold = st.sidebar.number_input("ğŸ”¢ **Z-Score Threshold**", value=3.0, step=0.1)
            # Calculate z-scores, handling NaNs
            z_scores = df[selected_columns].apply(lambda x: np.abs(stats.zscore(x, nan_policy='omit')))
            # Identify outliers
            outliers = z_scores > threshold
            # Any row with any outlier in selected columns
            outlier_mask = outliers.any(axis=1)
        elif test == "IQR":
            multiplier = st.sidebar.number_input("ğŸ“ **IQR Multiplier**", value=1.5, step=0.1)
            Q1 = df[selected_columns].quantile(0.25)
            Q3 = df[selected_columns].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - multiplier * IQR
            upper_bound = Q3 + multiplier * IQR
            # Identify outliers
            outliers = (df[selected_columns] < lower_bound) | (df[selected_columns] > upper_bound)
            # Any row with any outlier in selected columns
            outlier_mask = outliers.any(axis=1)
        elif test == "DBSCAN":
            eps = st.sidebar.number_input("ğŸ”§ **DBSCAN eps**", value=0.5, step=0.1)
            min_samples = st.sidebar.number_input("ğŸ”§ **DBSCAN min_samples**", value=5, step=1)
            scaler = StandardScaler()
            scaled_data = scaler.fit_transform(df[selected_columns].dropna())
            db = DBSCAN(eps=eps, min_samples=min_samples)
            db.fit(scaled_data)
            labels = db.labels_
            outliers_detected = labels == -1
            # Initialize a Series with all False
            outlier_mask = pd.Series(False, index=df.index)
            # Assign outlier status to the corresponding indices
            outlier_mask.loc[df[selected_columns].dropna().index] = outliers_detected
        elif test == "Isolation Forest":
            contamination = st.sidebar.number_input(
                "ğŸ§® **Isolation Forest Contamination**",
                value=0.05, 
                min_value=0.0, 
                max_value=0.5, 
                step=0.01
            )
            iso_forest = IsolationForest(contamination=contamination, random_state=42)
            # Fit the model
            iso_forest.fit(df[selected_columns].dropna())
            preds = iso_forest.predict(df[selected_columns].dropna())
            outliers_detected = preds == -1
            # Initialize a Series with all False
            outlier_mask = pd.Series(False, index=df.index)
            # Assign outlier status to the corresponding indices
            outlier_mask.loc[df[selected_columns].dropna().index] = outliers_detected

        # Add the 'Outlier' column, ensuring no NaNs
        df['Outlier'] = outlier_mask.fillna(False).astype(bool)
        num_outliers = df['Outlier'].sum()
        st.write(f"**Number of outliers detected:** {num_outliers}")
        
        # Optionally, display some statistics or a table of outliers
        if num_outliers > 0:
            st.subheader("ğŸ“‹ **Outlier Records**")
            st.write(df[df['Outlier']])
    else:
        st.warning("âš ï¸ Please select at least one numerical column for outlier detection.")
    return df

def download_enhanced_dataset(df):
    """
    Provides an option for users to download the enhanced dataset with outlier flags.

    Args:
        df (pd.DataFrame): The enhanced dataset.
    """
    st.header("ğŸ’¾ **Download Enhanced Dataset**")
    def to_excel(df):
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='Sheet1')
            writer.close()  # Corrected method to close the writer
        processed_data = output.getvalue()
        return processed_data

    excel_data = to_excel(df)
    st.download_button(
        label="ğŸ“¥ **Download Dataset with Outlier Flags**",
        data=excel_data,
        file_name='enhanced_dataset.xlsx',
        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

def main():
    """
    The main function that orchestrates the Streamlit application.
    """
    st.set_page_config(
        page_title="ğŸ“Š Outlier Detection and Analysis App",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    st.title("ğŸ“ˆ **Outlier Detection and Analysis App**")
    st.markdown("""
    Welcome to the **Outlier Detection and Analysis App**! This educational application allows you to:
    - ğŸ“¥ **Upload** your dataset (CSV or Excel).
    - ğŸ” **Filter** data based on custom conditions.
    - ğŸ§® **Aggregate** scores from multiple numerical columns.
    - ğŸ“Š **Visualize** data distributions (monovariate and multivariate).
    - ğŸ” **Detect** outliers using various statistical methods.
    - ğŸ’¾ **Download** the enhanced dataset with outlier flags.

    **Instructions:**
    1. **Upload** your dataset using the upload button.
    2. **Filter** the data by entering your conditions in the filter section.
    3. **Aggregate** scores if needed.
    4. **Visualize** the data distributions.
    5. **Choose** a statistical test to detect outliers.
    6. **Download** the enhanced dataset with outlier information.

    **Educational Notes:**
    - **Outliers** are data points that deviate significantly from the majority of the data.
    - Detecting outliers is crucial as they can impact statistical analyses and machine learning models.
    - Different statistical methods are suitable for different data distributions and scenarios.
    """)

    # Step 1: Upload Dataset
    df = upload_dataset()
    if df is not None:
        st.markdown("---")
        # Step 2: Filter Cases
        filtered_df = filter_cases(df)
        
        st.markdown("---")
        # Step 3: Aggregate Scores
        aggregated_df = aggregate_scores(filtered_df)
        
        st.markdown("---")
        # Step 4: Visualizations
        st.header("ğŸ“Š **Data Visualization**")
        col1, col2 = st.columns(2)
        with col1:
            plot_monovariate_distribution(aggregated_df)
        with col2:
            plot_multivariate_distribution(aggregated_df)
        
        st.markdown("---")
        # Step 5: Choose Statistical Test
        selected_test = choose_statistical_test()
        
        # Step 6: Identify Outliers
        outlier_df = identify_outliers(aggregated_df, selected_test)
        
        st.markdown("---")
        # Step 7: Download Enhanced Dataset
        download_enhanced_dataset(outlier_df)
        
        st.markdown("---")
        # Optional: Display the enhanced dataset
        st.header("ğŸ“‚ **Enhanced Dataset**")
        st.dataframe(outlier_df)
        
        st.subheader("ğŸ“Š **Dataset Statistics**")
        st.write(outlier_df.describe())

if __name__ == "__main__":
    main()
